To make container run continuously 
Docker update --restart unless-stopped docker_id-daalo

Images and Containers
  A docker image is a collection of bin/lib that are necessary for 
a s/w application to run.All these image are available on the cloud
site of docker know as hub.docker.com

  A running instances of an image is called as a container.Any number
of containers can be created from one docker image

DockerHost: The server where docker is installed and where we run the
docker containers is called as dockerhost

Docker client: This is a s/w which is responsible for accepting the 
docker commoands from the user and it passes these commands to another
background process called docker deamon

DockerDeamon: This is responsible for accepting the docker commands
from the docker client and route to work on either docker images 
or docker container or on the registry

Docker Registry: This is the location where all the docker images are preserved
It is classified into 2 types
1 Public registry   http://hub.docker.com
2 Private registry

Important docker commands
==========================

Working on docker images
===========================
1 To download a docker images
  docker pull image_name

2 To see the list of docker images
  docker image ls
  (or)
  docker images

3 To search for a docker image
  docker search image_name

4 To delete a docker image
  docker rmi image_name/image_id

5 To push a docker image into the docker registry
  docker push image_name/image_id

6 To save an image as a tar file
  docker save image_name/image_id

7 To untar a image tar file and make it as a docker image
  docker load image_name/image_id

8 To create a image from a container
  docker commit container_name/container_id  new_image_name

9 To create a docker image from a dockerfile
  docker build -t image_name .

10 To delete all the docker images that are not associated with any containers
   docker system prune -a

11 To get detailed info about a docker image
   docker image inspect image_name/image_id

Working on docker containers
====================================
12 To start a stopped container
   docker start container_name/container_id

13 To stop a running container
   docker stop container_name/container_id

14 To restart a running container
   docker restart container_name/container_id
   To restart a container after 30 seconds
   docker restart -t 30 container_name/container_id

15 To delete a stopped container
   docker rm container_name/container_id

16 To delete a running contianer
   docker rm -f container_name/container_id

17 To stop all the running containers
   docker stop $(docker ps -aq)

18 To delete all stopped containers
   docker rm $(docker ps -aq)

19 To delete all containers (running and stopped)
   docker rm -f $(docker ps -aq)

20 To see the list of running all running containers
   docker container ls

21 To see the see the list of all the  contianers(running and stopped)
   docker ps -a

22 To get detailed info about a container
   docker inspect container_name/container_id

23 To see the logs generated by a container
   docker logs container_name/container_id

24 To see the ports used by the container
   docker port container_name/container_id

25 To run any command or application in a container from outside the container
   docker exec -it container_name/container_id  command
    Eg: To open interactive bash shell in a continer
    docker exec -it container_name/container_id bash

26 To go into a container which is running in background
   docker attach container_name/container_id

27 To come out of the container without exit
   ctrl+p,ctrl+q

28 To see the list of running process in a container
   docker container top container_name/container_id

29 To export a container file system as a tar file
   docker container export container_name/container_id

30 To create a container from a docker image
   docker run image_name/image_id
   Run command options
   --------------------
   --name:  Used to give a name for a container
   -d:  Used to run a container in detached mode as a background process
   -it : Used to open interactive terminal in the container
   -rm : Used to delete a container on exit
   -e : Used to pass environment variables to container
   -p : Used for port mapping ie it will map the container(internal port)
        with the host post(external port)
        Eg:   -p 8080:80  Here 8080 is the host port and 80 is the container port
   -P : Used for automatic port mapping ie it will link the container port
        with some port number that is greater than 30000
   --link : Used to link multiple containers to create a micro services architecture
   -m : Used to put an upper limit on the max amount of memory that a container
        can use
   -c : Used to put an upper limits on the percentage of cpu that a container can use
   -ip: USed to assing a static ip to a contianer

Working on docker networks
==================================
31 To create a new docker network
   docker network create --driver network_type  network_name

32 To see the list of networks
   docker network ls

33 To get detailed info about a network
   docker network inspect networn_name

34 To attach a running contianer to a network
   docker network connect network_name/network_id  container_name/container_id

35 To detach a running  container from a network
   docker network disconnect network_name/network_id  container_name/container_id

36 To delete a network
   docker network rm network_name/network_id

Working on docker volumes
===============================
37 To create a docker volume
   docker volume create volume_name

38 To see the list of available volumes
   docker volume ls

39 To get detailed info about a volume
   docker volume inspect volume_name/volume_id

40 To delete a volume 
   docker volume rm volume_name/volume_id

============================================================================
Day 5
============================================================================
UseCase 1
----------------
Create an nginx container in detached mode and also perform 
the port mapping

1 docker run  --name webserver -d -p 8888:80 nginx

2 To access the nginx from the browser
  public_ip_dockerhost:8888

UseCase 2
----------------
Create a jenkins container in detached mode and perform automatic port mapping

1 Create the jenkins container
  docker run --name myjenkins -d -P jenkins

2 To check the mapped ports
  docker port myjenkins

3 To access the jenkins container from a browser
  public_ip_dockerhost:port_no_from_step2


UseCase 3
------------
Create an ubuntu container and open interactive terminal in it
docker run --name u1 -it ubuntu

UseCase 4
-------------
Create a centos container and open interactive terminal in it
docker run --name c1 -it centos

UseCase 5-
----------------
Create a postgres db as a container
docker run --name postgrespassword -d -e POSTGRES_PASSWORD=intelliqit postgres

UseCase 6
---------------
Create a mysql container and go into its interactive terminal,login into the
database as root user and create few sql tables

1 Create a mysql container
  docker run --name mydb -d -e MYSQL_ROOT_PASSWORD=intelliqit mysql:5

2 To open interactive bash shell in the container
  docker exec -it mydb bash

3 Login as mysql root user
  mysql -u root -p
  Password: intelliqit

4 To see the list of available databases
  show databases;

5 To move into any of the above databases
  use sys;

6 To create emp and dept tables here
  Open https://justinsomnia.org/2009/04/the-emp-and-dept-tables-for-mysql/

7 Copy the code for creating emp and dept tabels and paste in mysql container

8 To see the emp and dept tables
  select * from emp;
  select * from dept;


================================================================================
Day 6
================================================================================
Linking of docker containers
===================================
This is done to create a multi container architecture
which can be used as a Dev environment or testing environment
or CI-CD environment etc

This can be done in 3 ways

1  --link (run command option and it is depricated)
2 Docker compose
3 Docker Networking

Using the --link option
============================
UseCase-1
Start 2 busybox containers and link them with each other,check if they are pingables

1 Create a busybox container c1
  docker run  --name c1 -it busybox

2 Come out of the c1 container without exit
  ctrl+p,ctrl+q

3 Create another busybox container c2 and link it with the first container c1
  docker run  --name c2 -it --link c1:mybusybox  busybox

4 Check if c2 container is able to ping to c1
  ping c1  (It should ping)


UseCase 2
================
Create a mysql container and link it with a wordpress container
A wordpress developer should be able to create a wordpress website

1 Create a mysql container
  docker run  --name mydb -d -e MYSQL_ROOT_PASSWORD=intelliqit mysql:5

2 Create a wordpress container and link with mysql container
  docker run  --name wordpress -d -p 8989:80 --link mydb:mysql wordpress

3 To access the wordpress
  a) Launch any browser
  b) public_ip_of_dockerhost:8989


---------------------------------------------------------------------
UseCase 3
=============
Create a CI-CD environment where a jenkins container is linked with
2 tomcat containers name one tomcat as qaserver and other as prodserver

1 Create a jenkins container
  docker run --name jenkinsserver -d -p 5050:8080 jenkins

2 To access the home page of jenkins
  a) Launch any browser
  b) public_ip_of_dockerhost:5050

3 Create a tomcat container(qaserver) and link with the jenkins container
  docker run --name qaserver -d -p 6060:8080 --link jenkinsserver:jenkins tomcat

4 Create another tomcat container(prodserver) and link with the jenkins container
  docker run --name prodserver -d -p 7070:8080 --link jenkinsserver:jenkins tomcat

5 Check if all there containers are running
  docker container ls


=================================================================
UseCase - 4
Create a lamp environment using docker

1 Create a mysql database container
  docker run --name mydb -d -e MYSQL_ROOT_PASSWORD=intelliqit mysql

2 Create a apache container and link with mysql container
  docker run --name apache -d -p 9999:80 --link mydb:mysql httpd  

3 Create a php container and link with mysql and apache containers
  docker run --name php -d --link mydb:mysql --link apache:httpd php:7.2-apache

========================================================================
Day 7
========================================================================



UseCase-1
=================
Create a testing environment where a selenium hub container
should be linked with 2 node containers one with chrome
installed and other with firefox installed.The testers should be 
able to run the cross browser,cross platform automation
test scripts

1 Create a selenium hub image
  docker run --name hub -d -p 4444:4444 selenium/hub

2 Create a chrome node and link with the hub container
   docker run --name chrome -d -p 5901:5900 --link hub:selenium  
                                           selenium/node-chrome-debug

3 Create a firefox node and link with the hub container
  docker run --name firefox -d -p 5902:5900 --link hub:selenium 
                                           selenium/node-firefox-debug

4 Check if all 3 containers are running
  docker container ls

5 The above 2 containers are GUI containers and to access the GUI of
  these containers
  a) Install VNC viewer from https://www.realvnc.com/en/connect/download/viewer/
  b) Open vnc viewer
  c) public_ip_of_dockerhost:5901 and 5902
  d) Click on continue--->Enter password:secret

--------------------------------------------------------------------------
Docker Compose
=================
This is used for creating a multi contianer architecture using yaml files
The main advantage is it is reusable

Sample yaml file

---
intelliq:
 trainers:
  devops: sai
  aws: sheshi
 coordinators:
  devops: Lakshmi
  aws: Shailja
...

Installing docker compose
--------------------------------
1 Open https://docs.docker.com/compose/install/
2 Click on Linux tab and copy paste the below 2 commands

  sudo curl -L "https://github.com/docker/compose/releases/download/1.25.5/
      docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

  sudo chmod +x /usr/local/bin/docker-compose

3 To check the version of dockercompose
  docker-compose --version

UseCase 1
==============
Create a docker compose file for setting up a wordpress container and link 
 with a mysql container
---
version: '3'

services:
 mydb:
  image: mysql:5
  environment:
   MYSQL_ROOT_PASSWORD: intelliqit

 mywordpress:
  image: wordpress
  ports:
   - 9999:80
  links:
   - mydb:mysql
...

To start the containers
docker-compose up 
To start the containers indetached node
docker-compose up -d

To stop the containers
docker-compose stop

To stop and delete the containers
docker-compose down

To see the list of processes in the container
docker-compose ps

To start the stopped container
docker-compose start

To pause the executiong 
docker-compose pause

To unpause
docker-compose unpause


=========================================================================
Day 8
=======================================================================
Create a docker compose file for seeting up the CI-CD environment
where a jenkins contianer is linked with 2 tomcat contianer
vim docker-compose.yml
---
version: '3'

services:
 jenkinsserver:
  image: jenkins
  ports:
   - 5050:8080

 qaserver:
  image: tomcat
  ports:
   - 6060:8080
  links:
   - jenkinsserver:jenkins

 prodserver:
  image: tomcat
  ports:
   - 7070:8080
  links:
   - jenkinsserver:jenkins
...
=================================================================================
Docker compose file to setup the LAMP environment

vim docker-compose.yml

version: '3'

services:
 mydb:
  image: mysql
  environment:
   MYSQL_ROOT_PASSWORD: intelliqit

 apache:
  image: httpd
  ports:
   - 9090:80
  links:
   - mydb:mysql

 php:
  image: php:7.2-apache
  links:
   - mydb:mysql
   - apache:httpd

=================================================================================
Docker compose file to setup the selenium testing environment where
a hub container can be linked  with a chrome and firefox node containers

---
version: '3'

services:
 hub:
  image: selenium/hub
  ports:
   - 4444:4444

 chrome:
  image: selenium/node-chrome-debug
  ports:
   - 5901:5900
  links:
   - hub:selenium

 firefox:
  image: selenium/node-firefox-debug
  ports:
   - 5902:5900
  links:
   - hub:selenium


...

=====================================================================================Docker Volumes
================================================================
Containers are ephemeral but the data processed by a container
should be persistent.To achive this we can use volumes
A volume is an external device or an external directory
whcih is mounted on a container in such a way that even after
the container is delete the mounted volume data will be present

Docker uses 3 types of volumes
1 Simple docker volume
2 Sharable docker volumes
3 Docker volume container

Simple docker volume
----------------------
This is used only for preserving the data even though the 
container is deleted

==================================================================
Day 9
===================================================================
UseCase
-----------
Create a directory /data on the host machine
Create an ubuntu container and mount this /data
as a volume on this contianer.Create some files in this mounted
volume and check if the files are still available on the host
machine even when the container is deleted

1 Create a directory /data
  mkdir /data

2 Create an ubuntu container and mount /data as a volume
  docker run --name u1 -it -v /data ubuntu

3 In the ubuntu u1 container go into data folder(mounted volume)
  and create some files
  cd data
  touch file1 file2
  exit

4 Indentify the mounted locations
  docker inspect u1
  Go to "Mounts" sections and copy the "Source" path
  
5 Delete the container
  docker rm -f u1

6 Check if the data is still present on host machine
  cd "Source_path_from_step4"
  ls

Sharables Volumes
=======================
These volumes can be shared betwen multiple containers
and the changes done by one container will be reflected
to all other containers

UseCase
===========
Create a folder /data on the dockerhost.mount it as a volume on
centos container c1,later create another centos container c2
and this c2 should use the volume used by c1,create another
centos container c3 and this should use the volume used by c2
Delete all three containers and check if the data is still present 
on the host machine

1 Create /data folder
  mkdir /data

2 Start centos as a container and mount /data as a volume 
  docker run --name c1 -it -v /data centos

3 In the centos c1 container go into the volume and create files
  cd data
  touch file1 file2
  Come out of the container without exit (ctrl+p,ctrl+q)

4 Create another centos container c2 and this container should use
  the volume used by c1
  docker run --name c2 -it --volumes-from c1 centos

5 In the centos c2 container go into the volume and create files
  cd data
  touch file3 file4
  Come out of the container without exit (ctrl+p,ctrl+q)

6 Create another centos container c3 and this container should use
  the volume used by c2
  docker run --name c3 -it --volumes-from c2 centos

7 In the centos c3 container go into the volume and create files
  cd data
  touch file5 file6
  Come out of the container without exit (ctrl+p,ctrl+q)

8 Go into any of the 3 containers and we should see all the files
  docker attach c1 (or) c2 (or) c3
  ls
  exit

9 Identify the mounted location
  docker inspect c1
  Go to "Mounts" section and copy the "Source" path

10 Delete all the 3 containers
   docker rm -f c1 c2 c3

11 Check if the files are still available on the host machine
   cd "source path coped from step 9"
   ls

=========================================================================
Docker volume containers
==============================
These are by directional volumes ie the files from the
host can be accessed in the container and the files from the
container can be accesed on the host

UseCase
----------------
Create a volume "myvolume",Create some files in this volume
and attach it to a centos container.In the centos container
check if this data is available.Similary create some files
in the volume in the container and check if these files are
available on the host

1 Create a docker volume
  docker volume create myvolume

2 Identify the volume location
  docker volume inspect myvolume
  Copy the MountPoint path

3 Go to this mountpoint and create some files
  cd MountPoint+path_from_step2
  touch file1

4 Create a centos container and mount the volume on /tmp folder in the container
  docker run  --name c1 -it -v myvolume:/tmp centos

5 Go into the tmp folder in the container and check if the files from host
  are available
  cd tmp
  ls
  
6  Create few files
   touch file2 file3
  exit

7 Delete the centos container
  docker rm -f c1

8 Check if the data is still present
  cd MountPoint_path_from_step2
  ls

================================================================================

Creating customised docker images
====================================
This can be donw in 2 ways
1) Using the docker commit command
2) Using Dockerfile

Using the commit command
----------------------------
UseCase
-----------
Create a centos container and install git in it,Save this container as
an image and create a new container from thsi newly created image
We should see that git is already present

1 Create a centos container
  docker run  --name c1 -it centos

2 Update the yum repository and install git
  yum -y update
  yum install -y git
  git --version
  exit

3 Save the container as an image
  docker commit c1 mycentos

4 Delete the centos container
  docker rm -f c1

5 Check if a new image is created
  docker images

6 Create a new container from the above new image and check  of git is present
  docker run  --name c1 -it mycentos
  git --version

============================================================================
Day 10
============================================================================
Dockerfile
=================
This is used for creating customised docker images
Dockerfile is a simple text file which uses certain predefined
keywords for perfoming various activites related to image creation.

Important keywords used in Dockerfile
========================================
FROM: This is used to specify the base image from which we should
      create the customised docker image

MAINTAINER: Used to represent the name of the author or the organization
	    that is creating this dockerfile

RUN: This is used to run linux commands in the image,generally it is used
     for upgrading s/w packages and installing s/w applications in the image

CMD: This is used to run an application in the container even when the
     control is outside the container

ENTRYPOINT: Every docker container triggers a specific process when it
            starts and this is the known as the "default process"
            of the container and the the container will be running condition
            only as long as this default process runs,We can specify 
            what should be the default process if a container using this
            option

VOLUME :  Used to attach or mount a deafult volume to a container

EXPOSE: This is used to expose a container port so that it can  be mapped
         with a host port


COPY:  Used to copy files from host to container

ADD: Used to copy files from host to container but it can also download
     files from remote servers into the container

USER: This is used to specify the default user who should login into the
      container

WORKDIR: Used to specify the default directory where the command should be
         executed in a container

SHELL: USed to specify what shell should run in the container Eg: bash,sh,ksh

LABEL:  Used to give a default label to container

STOPSIGNAL:  USed to specify the key sequence that has to be passes to
             stop the container


====================================================
Create a dockerfile from nginx base image and specify the 
maintainer as intelliqit

1 vim dockerfile

FROM nginx
MAINTAINER intelliqit

2 To build an image from the above dockerfile
  docker build -t mynginx .



3 Check if a new image called mynginx is created
  docker images

====================================================
Create a dockerfile from centos base image and install git in it

1 vim dockerfile

FROM centos
MAINTAINER intelliqit
RUN yum -y update
RUN yum install -y git

2 To build an image from the above dockerfile
  docker build -t mycentos .

3 Check if a new image called mycentos is created
  docker images

4 Create a container from the above image and check if git is installed
  docker run --name c1 -it mycentos
  git --version

==================================================================
Cache Busting
===================
Whenever we create an image from a dockerfile docker stores all
the executed instructions in the "dockercache",next time if we
make modifications to the dockerfile and rebuild a new image
docker reads all the previously executed instructions from the '
dockercache and it will execute only the new instructions
This is a time saving machanism provided by docker

Eg:
FROM ubuntu
RUN apt-get update
RUN apt-get install -y git

If we create an image from the above dockerfile it save all these instructions
in the dockecache and alter if we add the below statement
RUN apt-get install -y tree
and if we build an image from this docker file it will execute on the 
latest instruction

The disadvantage is if we edit the docker file after a huge timegap
then we can end up installing s/w from a reposiotry that was updated 
log time back

To overcome this we can use "cache busting" ie we can tell docker
to build an image from the dockerfile without reading previosuly
executed instructions from the dockercache

docker build --no-cache -t myubuntu .

====================================================================
Create a dockerfile from ubuntu base image and mount /data
as the deafult volume

1 vim dockerfile
FROM ubuntu
MAINTAINER intelliqit
VOLUME /data

2 Create an image from the above dockerfile
  docker build -t myubuntu .

3 Create a container from the above image
  docker run --name u1 -it myubuntu

4 Go into the mounted volume and create few file
  cd data
  touch file1 file2
  exit

5 Check the mounted location
  docker inspect u1
  Go to "Mounts" section and copy the "Source" path

6 Delete the container
  docker rm -f u1

7 Check if the data is still present on the host machine
  cd "Source_path_from_step5"
  ls

==================================================================
Day 11
===================================================================
Create a dockerfile from nginx base image and expose 90 as
the container port

1 vim dockerfile
FROM nginx
MAINTAINER intelliqit
EXPOSE 90

2 To build an image from the above dockerfile
  docker build -t mynginx .

3 Create a container from the above image
  docker run --name n1 -d -P mynginx

4 Check the port of the container
  docker port n1

=======================================================================

Create a dockerfile from jenkins base image and make the deafult user
as root and also install git amd maven

1 vim dockerfile

FROM jenkins
MAINTAINER intelliqit
USER root
RUN apt-get update
RUN apt-get install -y git maven

2 Create an image from the above file
  docker build -t myjenkins .

3 Create a container from the above image
  docker run --name j1 -d -P myjenkins

4 Go into the bash shell of the container and check who is the 
  default user and also check if the git and maven are present
  docker exec -it j1 bash
  whoami
  git --version
  mvn --version

==============================================================================
Day 12
==============================================================================
Create a dockerfile from ubuntu dockerimage and install java in
it and download jenkins.war.
When we start the contaienr it shoudl execute
java -jar jenkins.war as the default process

1 vim dockerfile
FROM ubuntu
MAINTAINER intelliqit
RUN apt-get update
RUN apt-get install -y openjdk-8-jdk
ADD http://mirrors.jenkins.io/war-stable/latest/jenkins.war /
ENTRYPOINT ["java","-jar","jenkins.war"]
EXPOSE 8080

2 Create an image from the dockerfile
  docker build -t myubuntu .

3 Create a container and check if jenkins is running
  docker run  --name u1 -it myubuntu
  This will generate the logs of jenkins

4 To access the jenkins from the brpwser
  public_ip_of_dockerhost:8080

=============================================================================
Create a dockerfile from centos base image and install
httpd in it.Copy index.html into this and make httpd as the
default process of the container

1 vim index.html
<html>
 <body>
         <h1>Welcome to IntelliQIt</h1>
  </body>
</html>

2 vim dockerfile
FROM centos
MAINTAINER intelliqit
RUN yum -y update
RUN yum install -y httpd
COPY index.html /var/www/html
ENTRYPOINT ["/usr/sbin/httpd","-D","FOREGROUND"]
EXPOSE 80

3 Create an image from the above file
  docker build -t mycentos .

4 Create a container from the above image
  docker run --name c1 -d -P mycentos

5 Check if we can access this container from browser
  public_ip_dockerhost:port_no_from_step4

============================================================================
Create a dockerfile from ubuntu image and make it behave
like an nginx container

1 vim dockerfile
FROM ubuntu
MAINTAINER intelliqit
RUN apt-get update
RUN apt-get install -y nginx
ENTRYPOINT ["/usr/sbin/nginx","-g","daemon off;"]
EXPOSE 80

2 Create an image from the above dockerfile
  docker build -t myubuntu .

3 Create a container a from the above image
  docker run --name c1 -d -P myubuntu

4 to access the nginx from browser
  public_ip_dockerhost:port_no_from_step3

=============================================================================
Day 13
========================================================================

Docker Networking
=====================
Docker uses 4 types os networks
1 Bridge: This is the deafult network of docker when contianers are
          running on a single docker host

2 Host: This is used when we want to run a single container on a dockerhost
         and this contianer communicates only with the host machine

3 Null: This is used for creating isolated containers ie these containers
        cannot communicate with th host machine or with other containers

4 Overlay: This is used when containers are running in a distributed environment
           on multiple linux servers


UseCase
===============
Create 2 bridge networks intelliq1 and intelliq2
Create 2 busybox containers c1,c2 and c3
c1 and c2 should run on intelliq1 network and shoul ping each other
c3 should run on intelliq2 network and it should not be able to ping c1 or c2
Now put c2 on intelliq2 network,since c2 is on both intelliq1 and intelliq2
networks it should be able to ping to both c1 and c3
but c1 and c3 should not ping each other directly

1 Create 2 bridge networks
  docker network create --driver bridge intelliq1
  docker network create --driver bridge intelliq2

2 Check the list of available networks
  docker network ls

3 Create a busybox container c1 on intelliqi1 network
  docker run --name c1 -it --network intelliq1 busybox
  Come out of the c1 container without exit ctrl+p,ctrl+q

4 Identify the ipaddress of c1
  docker inspect c1

5 Create another busybox container c2 on intelliq1 network
  docker run --name c2 -it --network intelliq1 busybox
  ping ipaddress_of_c1    (It will ping)
  Come out of the c2 container without exit ctrl+p,ctrl+q

6 Identify the ipaddress of c2
  docker inspect c2

7 Create another busybox container c3 on intelliq2 network
  docker run --name c3 -it --network intelliq2 busybox
  ping ipaddress_of_c1  (It should not ping)
  ping ipaddress_of_c2  (It should not ping)
  Come out of the c3 container without exit ctrl+p,ctrl+q

8 Identify the ipaddress of c3
  docker inspect c3 

9 Now attach intelliq2 network to c2 container
  docker network connect intelliq2 c2

10 Since c2 is now on both intelliq1 and intelliq2 networks it should ping
   to both c1 and c3 containers
   docker attach c2
   ping ipaddress_of_c1  (It should  ping)
   ping ipaddress_of_c3  (It should  ping)
   Come out of the c2 container without exit ctrl+p,ctrl+q

11 But c1 and c3 should not ping each other
   docker attach c3
   ping ipaddress_of_c1  (It should not ping)

Command to create a bridge network with a specific subnet
docker network create  --driver bridge --subnet=192.168.2.0/24 intelliq3

==============================================================================
======================================================================
Container Orchestration
=============================
This is the process of running docker containers on a distributed
environment so that they can be orchestrated together

Advantages
==============
1 Load Balancing
  We run run multiple replicas on multiple docker hosts and thus
distribute the load between these servers.On all these replicas
we can have only one service running

2 Scalling
  Depending on the business requirement we can scale up or down
the number of replicas without the end user experencing any down time

3 Disaster Recovery and High Availability
  In case a container crashes or if the docker host itself crashes
then  container orchestration tools move the replicas running on that
docker host to some other dockerhost in the cluster.It will always 
try to maintain the desired count of replicas

4 Rolling Updates
  The services running in a production environment should be updated to
a higher version or rolled back to a lower version without the end user 
experiencing any down time.

Pouplar Container Orchestration Tools
------------------------------------------
1 Docker Swarm
2 Kubernetes
3 Openshift
4 Apache Mesos

Docker Swarm
==============
This is a contianer orchestration tool of docker and it helps us to
managed docker containers running on multiple servers

The main machine where docker swarm is initilised is called as MAanger
The remianing machines that take the work load are called as Workers.



Setup of Docker Swarm
=======================
1 Create few AWS instances and aanme as Manager,Worker1 etc

2 Install docker in all of them

3 Change the hostname
  vim /etc/hostname
  Remove the content and replace it with Manager (or) Worker1 (or) Worker2

4 To initilise the swarm manager
  a) Connect to Maanger AWS instance uisng git bash
  b) docker swarm init --advertise-add ipadrress_of_manager
     This command will create a docker swarm and it will genrate a token id
     as output,We should this token id in the Worker machine and then they will
     join swarm as workers
  c) Connect to Workers and execute the token id of 4-b step

Ports used by Swarm
=======================
TCP port 2376 for secure Docker client communication. This port is required for Docker Machine to work. Docker Machine is used to orchestrate Docker hosts.

TCP port 2377. This port is used for communication between the nodes of a Docker Swarm or cluster. It only needs to be opened on manager nodes.

TCP and UDP port 7946 for communication among nodes (container network discovery).
UDP port 4789 for overlay network traffic (container ingress networking).


======================================================================
Load Balancing
===================
1 Start nginx with 5 repliacs and perfrom port mapping
  docker service create --name webserver -p 8888:80 --replicas 5 nginx

2 To check if 5 replicas are distributed on Manager and Workers
  docker service ps webserver

3 To access the nginx from a browser
  public_ip_of_manager/Worker1/Worker:8888


==========================================================================
1 Create mysql with 3 replicas and check if these 3 replicas are distributed on 
  manager and workers
  docker service create --replicas 3 --name mydb -d 
                                   -e MYSQL_ROOT_PASSWORD=intelliqit mysql:5

2 Check if 3 replicas are running on the cluster
  docker service ps mydb


============================================================================
Scalling
===============
Create tomcat with 3 replicas and later scale it up to 7
and later scale down to 2

1 Create tomcat with 3 replicas
  docker service create --name appserver -p 9090:8080 
                                          --replicas 3 tomcat

2 Check if 3 replicas are running in the cluster
  docker service ps appserver

3 Scale the replicas count to 7
  docker service scale appserver=7

4 Check if 7 replicas are running in the cluster
  docker service ps appserver

5 Scale it down to 2 replicas
  docker service scale appserver=2

8 Check if 2 replicas are running in the cluster
  docker service ps appserver


=======================================================================
Day 14
==========================================================================
Rolling updates
=====================
Create redis:3 with 5 replicas and update it to redis:4
later roll back to redis:3

1 Create redis:3 with 5 replicas
  docker service create --name myredis --replicas 5  redis:3

2 Check if 5 replicas of redis:3 are running
  docker service ps myredis

3 Perform a rolling update from redis:3 to redis:4
  docker service update --image redis:4 myredis:3

4 Check if 5 replicas of redis:3 are shut down and redis:4 are running
  docker service ps myredis

5 Perform a roll back from redis:4 to redis:3
  docker service update --rollback myredis

6 Check if redis:4 is shutdown and redis:3 is running
  docker service ps myredis

=========================================================================
1 To remove a node from swarm via Manager
  docker node update --availability drain node_name 
  Eg: For Worker1 to leave the swarm
  docker node update --availability drain Worker1

2 To make Worker1 rejoin docker swarm
  docker node update --availability active Worker1

3 Workers can also leave swarm
  a) Connect to Worker2 using git bash
     docker swarm leave
  b) On Manager check the status of nodes
     docker node ls
     It will show worker2 as "Down"
  c) To remove this Worker2 from the cluster
     docker node rm Worker2

4 Manager cam leave swarm
  docker swarm leave --force

5 To generate the token id to a machine to join swarm as worker
  docker swarm join-token worker

6 To generate the token id to a machine to join swarm as manager
  docker swarm join-token manager

7 To promote Worker1 as manager
  docker node promote Worker1

8 To demote a Worker1 from manager to worker
  docker node demote Worker1

======================================================================
FailOver Scnenarios
==========================
Create httpd with 6 replicas and delete one replica running on the manager
Check if all 6 replicas are still running

Drain Worker1 from the docker swarm and check if all 6 replicas are running
on Manager and Worker2,make Worker1 rejoin the swarm

Make Worker2 leave the swarm and check if all the 6 replicas are
running on Manager and Worker1

1 Create httpd with 6 replicas
  docker service create  --name webserver -p 9090:80 --replicas 6 httpd

2 Check the replicas running on Manager
  docker service ps webserver | grep Manager

3 Check the container id
  docker container ls

4 Delete a replica
  docker rm -f container_id_from_step3

5 Check if all 6 replicas are running
  docker service ps webserver

6 Drain Worker1 from the swarm
  docker node update --availability drain Worker1

7 Check if all 6 replicas are still running on Manager and Worker2
  docker service ps webserver

8 Make Worker1 rejoin the swarm
  docker node update --availability active Worker1

9 Make Worker2 leave the swarm
  Connect to Worker2 using git bash
  docker swarm leave
  Connect to Manager
  
10 Check if all 6 replicas are still running
   docker service ps webserver

=====================================================================
Day 15
======================================================================
FailOver Scenarios of Managers
====================================
If a worker instance crashses all the replicas running on that
worker will be moved to the Manager or the other workers.
If the Manager itself crashes the swarm becomes headless 
ie we cannot perfrom container orchestration activites in this
swamr cluster

To avoid this we should maintain multiple managers
Manager nodes have the status as Leader or Reachable

If one manager node goes down other manager becomes the Leader
Quorum is resonsible for doing this activity and if uses a RAFT
algorithm for handling the failovers of managers.Quorum also 
is responsible for mainting the min number of manager

Min count of manager required for docker swarm should be always
more than half of the total count of Managers

Total Manager Count  -    Min Manager Required
      1              -           1
      2              -           2
      3              -           2
      4              -           3
      5              -           3
      6              -           4
      7              -           4

Though having multiple mmanager is good to handle fail over scenarios
of Manager it generally slows down the speed of the orchestration
activiites as Quorum has to take approval from all the Manager
to perfrom an orchestration activity

============================================
Day 16
=============================================
Overlay network
==================
This is the deafult network used by docker swarm
and it perfroms network load balancing
ie even if donot have a replica running on a specific node
still we will be able to access that replica service via that node

UseCase
=============
Create 2 custom overlay networks intelliq1 intelliq2
Create htttpd as a service in swarm on the intelliq1 network
Create tomcat as a service in swarm on the default overlay (ingres) 
network and later perform a rolling network update to intelliq2 network

1 Create 2 overlay networks
  docker network create --driver overlay intelliq1
  docker network create --driver overlay intelliq2

2 Check if 2 new networks are create
  docker network ls

3 Start httpd with 5 replicas on intelliq1 network
  docker service create --name webserver -p 8888:80 --replicas 5
                                           --network intelliq1 httpd


4 Check if httpd is running on intelliq1 network
  docker service inspect webserver
  This command generates the output in JSON file format 
  To get the above output in simple text format
  docker service inspect webserver  --pretty

5 Start tomcat with 5 replcias on the defult ingres network
  docker service create --name appserver -p 9090:8080 --replicas 5 tomcat

6 Perfrom a rolling network update to intelliq2 network
  docker service update --network-add intelliq2 appserver

7 Check if tomcat in now running on intelliq2 network
  docker service inspect appserver  --pretty

Note: To remove a service from a  network
  docker service update --network-rm network_name service_name












Docker Stack
====================
This is used for creating a multi container architecture using
docker compose and deploy it in the swarm cluster

docker compose + swarm = docker stack
docker compose + kubernetes = kompose

1 To see the list of stacks
  docker stack ls

2 To create a stack
  docker stack deploy -c stack_filename/docker_compose_file  stack_name

3 To see the list of nodes where the stack services are running
  docker stack ps stack_name

4 To see the list of services in a stack
  docker stack service stack_name

5 To delete a stack
  docker stack rm stack_name

============================================================================
Create a docker stack file for wordpress and mysql
1 vim stack1.yml
---
version: '3'

services:
 mydb:
  image: mysql:5
  environment:
   MYSQL_ROOT_PASSWORD: intelliq

 mywordpress:
  image: wordpress
  ports:
   - 5050:80
  deploy:
   replicas: 3
...

2 To deploy this stack service
  docker stack deploy -c stack1.yml wordpress

3 To see where the  stack replicas are running
  docker stack ps wordpress

4 To remove the entire stack
  docker stack rm wordpress

==========================================================================
Create a stack file where 2 replicas of jenkins
3 replicas of tomcat as qaserver and 4 replicas of tomcat
as prodserver,
jenkins replicas should run only on manager
tomcat qaserver replicas only on worker1
tomcat prodserver replicas only on worker2

vim stack2.yml
services:
 jenkins:
  image: jenkins
  ports:
   - 5050:8080
  deploy:
   replicas: 2
   placement:
    constraints:
     - node.hostname == Manager

 qaserver:
  image: tomcat
  ports:
   - 6060:8080
  deploy:
   replicas: 3
   placement:
    constraints:
     - node.hostname == Worker1

 prodserver:
  image: tomcat
  ports:
   - 7070:8080
  deploy:
   replicas: 4
   placement:
    constraints:
     - node.hostname == Worker2
    

To deploy the services in swarm
docker stack deploy -c stack2.yml ci-cd

To check if all the serivces are deployed accoring to constraints
docker stack ps ci-cd

To delete the stack
docker stack rm ci-cd

==============================================================
Day 17
===============================================================


UseCase
===============
Create a docker stack file to setup the selenium testing environment
and also put an upper limit on the h/w allocation

1 vim stack3.yml
---
version: '3'

services:
 hub:
  image: selenium/hub
  ports:
   - 4444:4444
  deploy:
   replicas: 1
   resources:
    limits:
     cpus: "0.1"
     memory: "200M"

 chrome:
  image: selenium/node-chrome-debug
  ports:
   - 5901:5900
  deploy:
   replicas: 2
   resources:
    limits:
     cpus: "0.01"
     memory: "100M"

 firefox:
  image: selenium/node-firefox-debug
  ports:
   - 5902:5900
  deploy:
   replicas: 2
   resources:
    limits:
     cpus: "0.01"
     memory: "100M"

2 To deploy the the services from the above stack file
  docker stack deploy -c stack3.yml selenium

==================================================================
Docker secrets
====================
This is a feature of docker swarm using which we can pass encrypted
data to replicas running in the swarm cluster
These secrets are created on the host machine and then can be accessed
from the replicas in swarm but the content cannot be modified by the
replicas in swarm

1 To create a secret and pass some data into it
  echo "Hello IntelliQIT" | docker secret create mysecret -

2 To see the list of secrets
  docker secret ls

3 Create redis:alpine service with 3 replicas and add the secret to it
  docker service create --name redis --replicas 3 --secret mysecret redis:alpine

4 To check if this secret is available in the container
  docker container ls
  Copy the container id of the redis:alpine
  docker exec -it container_id cat /run/secrets/mysecret

======================================================
Secrets can be added to already running services  in swarm in
a rollign update fashion and also removed in a rolling rollback
manner

UseCase
============
Create httpd with 5 replicas and later add the secret to it
also remove the secret

1 Create httpd with 5 replicas
  docker service create --name webserver -p 8989:80  httpd

2 Add a secret in a rolling update manner
  docker service update --secret-add mysecret webserver

3 Check if the secret data is available
  docker container ls
  Select the container id of onew replica of httpd
  docker exec -it container_id cat /run/secrets/mysecret

4 To remove the secret in a rolling rollback manner
  docker service update --secret-rm mysecret webserver
====================================================================

Day 18
===================================================================
Create a secret for mysql database password
and pass it to the docker stack file

1 Create a secret
  echo "intelliqit" | docker secret create db_password -

2 Check if the secret is created or not
  docker secret ls

3 Create a docker stack file to use the above secret
vim stack5.yml
---
version: '3.1'
services:
 mydb:
  image: mysql:5
  environment:
   MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_password
  secrets:
   - db_password

 mywordpress:
  image: wordpress
  ports:
   - 5555:80
  deploy:
   replicas: 3

secrets:
 db_password:
  external: true
...

To deploy the stack services
docker stack deploy -c stack5.yml wordpress

To check where the replicas are running
docker stack ps wordpress
===============================================================
Create 3 secrets for postgres user,password and db
and pass them to the stack file

1 Create secrets
  echo "intelliqit" | docker secret create pg_password -
  echo "myuser" | docker secret create pg_user -
  echo "mydb" | docker secret create pg_db -

2 Check if the secrets are created
  docker secret ls

3 Create the docker stack file to work on these secrets
  vim stack6.yml
---
version: '3.1'
services:
  db:
    image: postgres
    environment:
      POSTGRES_PASSWORD_FILE: /run/secrets/pg_password
      POSTGRES_USER_FILE: /run/secrets/pg_user
      POSTGRES_DB_FILE: /run/secrets/pg_db
    secrets:
     - pg_password
     - pg_user
     - pg_db

  adminer:
    image: adminer
    restart: always
    ports:
      - 8080:8080
    deploy:
     replicas: 2

secrets:
    pg_password:
     external: true
    pg_user:
     external: true
    pg_db:
     external: true

...

============================================================================
Day 19
============================================================================
Working on docker registry
================================
Docker registry is the location where customised docker images
are stored.
This is of 2 types
1 Docker public registry
2 Docker private registry

Docker public registry
----------------------------
1 Signup for a account on hub.docker.com
2 Create a customised docker centos images
  a) docker run --name c1 -it centos
  b) Update the yum reposiotry and install git
     yum -y update
     yum install -y git
     exit
3 Save this container as an image
  docker commit c1 intelliqit/mycentos

4 Login into docker hub
  docker login
  Password:

5 Push the customised docker image
  docker push  intellqiit/mycentos

==================================================================

Create docker local registry and push an alpine image into it

1 Create a local registry
  docker run --name lr -d -p 5000:5000 registry

2 Download an alpine image
  docker pull alpine

3 Tag this image with the local registry
  docker tag localhost:5000/alpine

4 Push this image into the local registry
  docker push localhost:5000/alpine

======================================================================
Kubernetes
======================

Menions: This is an individual node used in kubernetes
Combination of these minions is called as Kubernetes cluster

Master is the main machine which triggers the container orchestraion
It distributes the work load to the Slaves

Slaves are the nodes that accept the work load from the master
and handle activites load balancing,autoscalling,high availability etc

=============================================================================
Day 20
==============================================================================

kubeadm: This is an application that is responible for creating the 
Master node and it also stores info about the salves

kubeapi: This is an application that runs on the salves and it it
accepts the instructions from kubeadm and executes them on the slaves

kubectl: This is an application that triggers the kubernetes commands

Kubenrnetes uses various of types of Object

1 Pod: This is a layer of abstraction on top of a container.This is the samallest
  object that kubernetes can work on.In the Pod we have a container.
  The advantage of using a Pod is that kubectl commands will work on the Pod and the 
  Pod communicates these instructions to the container.In this way we can use the
  same  kubectl irresepective of which technology containers are in the Pod.

2 Service: This is used for port mapping and network load balancing

3 NameSpace: This is used for creating partitions in the cluster.Pods running
 in a namespace cannot communicate with other pods running in other namespace

4 Secrets: This is used for passing encrypted data to the Pods 

5 ReplicaSet: This is used for managing multiple replicas of a Pod to perform
  activites like load balancing and autoscallin

6 Deployment: This used for perfroming all activites that a Replicaset can do
  it can also handle rolling update

Setup of Kubernetes
===============================
Free
===========
1 http://katakoda.com
(or)
2 http://playwithk8s.com

Paid
==============
1 Signup for a Google cloud account
2 Click on Menu icon on top right corner--->Click on Kubernetes Engine-->Clusters
3 Click on Create cluster--->Click on Create



================================================================
Kubernetes performs container orchestration uisnd certail definition
file.These files are created using yml and they hafve 4 top level
fields

apiVersion:
kind:
metadata:
spec:

apiVersion: Every kubernetes object uses a specific Kubernetes code
library that is called apiVersion.Only once this code library is imported
we can start working on specific objects

kind: This represents the type of Kubernetes object that we want to us
      eg: Pod,Replicaset,Service etc

metadata: Here we give a name to the Kubernetes object and also some
          labels.These labels can be used later for performing group
          activites

spec: This is where we store info about the exact docker image,container name
      environment varibales,port mapping etc


Kind              apiVersion
=================================
Pod               v1
Service           v1
NameSpace         v1
Secrets           v1
ReplicaSet        apps/v1
Deployment        apps/v1

==============================================================================
UseCase-1
Create a pod definition file to start an nginx in a pod 
name the pod as nginx-pod,name the container as appserver

vim pod-defintion1.yml

---
apiVersion: v1
kind: Pod
metadata:
 name: nginx-pod
 labels:
  author: intellqit
  type: reverse-prox
spec:
 containers:
  - name: appserver
    image: nginx
...

To create a pod from the above file
kubectl create -f pod-defintion1.yml

To see the list of pods
kubectl get pods

To see the pods along with the ipaddress and name of the slave where it is running
kubectl get pods -o wide

To delete the pods created from the above file
kubectl delete -f pod-definition1.yml

============================================================================
UseCase 2
Create a pod definition file for starting a posgrest container
with a name mydb in a pod called postgre-pod.Also pass the necessary 
environment variables

vim pod-definition2.yml
---
apiVersion: v1
kind: Pod
metadata:
 name: postgres-pod
 labels:
  author: intelliqit
  type: database
spec:
 containers:
  - name: mydb
    image: postgres
    env:
     - name: POSTGRES_PASSWORD
       value: myintelliqit
     - name: POSTGRES_USER
       value: myuser
     - name: POSTGRES_DB
       value: mydb

========================================================================

UseCase 3
Create a pod defintion file to start a jenkins container in a pod
called jenkins-pod,also perform port mapping to access the jenkins
from a browser

vim pod-definition3.yml
---
apiVersion: v1
kind: Pod
metadata:
 name: jenkins-pod
 labels:
  author: intelliqit
  ci: cd
spec:
 containers:
  - name: myjenkins
    image: jenkins
    ports:
     - containerPort: 8080
       hostPort: 8080

=============================================================================
Day 21
==============================================================================
ReplicationController
=======================
This is a high level Kubernets object that can be used for handling 
multiple replicas of a Pod.Here we can perfrom Load Balancing
and Scalling

ReplicationController uses keys like "replicas,template" etc in the "spec" section
In the template section we can give metadata related to the pod and also use
another spec section where we can give containers information

Create a replication controller for creating 3 replicas of httpd
vim repilication-controller.yml
---
apiVersion: v1
kind: ReplicationController
metadata:
 name: httpd-rc
 labels:
  author: intelliqit
spec:
 replicas: 3
 template:
  metadata:
   name: httpd-pod
   labels:
    author: intelliqit
  spec:
   containers:
    - name: myhttpd
      image: httpd
      ports:
       - containerPort: 80
         hostPort: 8080

To create the httpd replicas from the above file
kubectl create -f replication-controller.yml

To check if 3 pods are running an on whcih slaves they are running
kubectl get pods -o wide

To delete the replicas
kubectl delete -f replication-controller.yml


============================================================================

ReplicaSet
===================
This is also similar to ReplicationController but it is more
advanced and it can also handle load balancing and scalling
It has an additional field in spec section called as "selector"
This selector uses a child element "matchLabels" where the
it will search for Pod based on a specific label name and try to add
them to the cluster

Create a replicaset file to start 4 tomcat replicas  and then perform scalling
vim replica-set.yml
---
apiVersion: apps/v1
kind: ReplicaSet
metadata:
 name: tomcat-rs
 labels:
  type: webserver
  author: intelliqit
spec:
 replicas: 6
 selector:
  matchLabels:
   type: webserver
 template:
  metadata:
   name: tomcat-pod
   labels:
    type: webserver
  spec:
   containers:
    - name: mywebserver
      image: tomcat
      ports:
       - containerPort: 8080
         hostPort: 9090

To create the pods from the above file
kubectl create -f replica-set.yml

Scalling can be done in 2 ways
a) Update the file and later scale it
b) Scale from the coomand prompt withbout updating the defintion file

a) Update the file and later scale it
  Open the replicas-set.yml file and increase the replicas count from 4 to 6
  kubectl replace -f replicas-set.yml
  Check if 6 pods of tomcat are running
  kubectl get pods

b) Scale from the coomand prompt withbout updating the defintion file
   kubectl scale --replicas=2 -f replica-set.yml


Deployment
================

This is also a high level Kubernetes object which can be used for
scalling and load balancing and it can also perfrom rolling update

Create a deployment file to run nginx:1.7.9 with 3 replicas
Later perform a rolling update to nginx:1.9.1

vim deployment1.yml
---
apiVersion: apps/v1
kind: Deployment
metadata:
 name: nginx-deployment
 labels:
  author: intelliqit
  type: proxyserver
spec:
 replicas: 3
 selector:
  matchLabels:
   type: proxyserver
 template:
  metadata:
   name: nginx-pod
   labels:
    type: proxyserver
  spec:
   containers:
    - name: nginx
      image: nginx:1.7.9
      ports:
       - containerPort: 80
         hostPort: 8888
 
To create the deployment from the above file
kubectl create -f deployment.yml

To check if the deployment is running
kubectl get deployment

To see if all 3 pod of nginx are running
kubectl get pod

Check the version of nginx
kubectl describe pods nginx-deployment | less       (nginx:1.7.9)

Perform a rolling update to nginx:1.9.1
kubectl --record deployment.apps/nginx-deployment set image                           deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1

To check if the update the has happened
kubectl describe pods nginx-deployment | less      (nginx:1.9.1)




Kompose
=================
Implementing docker compsoe can be done using Kompose
docker compose + docker swarm = docker stack
docker compose + Kubernetes = Kompose

Installing Kompose
======================
Open  

https://www.digitalocean.com/community/tutorials/how-to-migrate-a-docker-compose-workflow-to-kubernetes


till 14 june notes
docker latest




















































































 































































































































 




























































  v 
















































































   




 













































































  






































  











































































































































 


















































































   













 


 
  














































 
 















































































































  































































 








































































 
